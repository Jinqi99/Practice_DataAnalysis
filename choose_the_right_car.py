# -*- coding: utf-8 -*-
"""Choose_the_right_car.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cgYRtilstqM-6OBbjrFBxh0IQ4OGIqsG

Dataset from [Kaggle: Car information dataset](https://www.kaggle.com/datasets/tawfikelmetwally/automobile-dataset)

目的：機械学習の手法を用いて、将来的に自分の需要および好みに合う車を選定するための練習することが目的であります。

## 前処理
"""

#ライブラリをインポートする
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

#Google Driveに接続する
from google.colab import drive
drive.mount('/content/drive')

#データセットを読み込む
data= pd.read_csv('/content/drive/MyDrive/Automobile.csv')

#最初の幾つのデータセットを出力する
data.head()

#各列ごとに平均や標準偏差、最大値、最小値、最頻値などの要約統計量を取得する
data.describe()

#データセットの形状を示す
data.shape

"""398行9列、データ量が結構多いですね。"""

#データセットの要素の要素型を示す
data.dtypes

#データセットの列名を示す
data.columns

"""自分は英語より日本語の方が得意のため、列の名前の日本語訳もつきます。

以下は日本語訳である。

目録([ 名前,燃費,気筒数,排気量,馬力,重量,加速度,モデル年,生産地 ])

## これからのコードの構成に関して
　データセットの列が結構多くて、全部の列について分析したら、結果が見づらくなるので、自分のいくつか興味のある列だけについて、分析させてもらいます。
"""

#データを良く観察するために、エンジンの加速度と燃費の散布図を生成する
plt.figure(figsize=(8, 6))
plt.scatter(data['acceleration'], data['mpg'])
plt.xlabel('acceleration')
plt.ylabel('MPG')
plt.title('Acceleration vs. MPG')
plt.show()

"""加速度と燃費は一定的な関係性があるみたいが少々弱い気がしているので、ここでは、「特徴量を選び直した方が良いのか」か「SVMとかの方法を用いて、データを解析するのか」二択の中に迷っています。

ーーーーーーーーーーーーーーーーー


機械学習のレポートであるため、「SVMとかの方法を用いて、データを解析するのか」の方法を選択しました。
"""

#年式の特徴量も加えてみます。
import pandas as pd
df = pd.DataFrame(data)
df['model_year'] = data.model_year
df.head()

#グラフで各特徴量の関係性をみてみましょう
import seaborn as sns
sns.pairplot(df, hue="model_year")

from sklearn.model_selection import train_test_split

feature = df.loc[:, ['acceleration', 'mpg']]#　":"は行を全部取ってくる
model_year = df.loc[:, ['model_year']]

x_feature, y_feature, x_model_year, y_model_year = train_test_split(feature, model_year, train_size=0.8, random_state=3)
x_feature.head()

from sklearn.preprocessing import StandardScaler

#(-3 ~ 3)
sc = StandardScaler()

#外れ値に強いの正規化
sc.fit(x_feature)#準備
x_feature_std = sc.transform(x_feature)
y_feature_std = sc.transform(y_feature)
print(x_feature_std)

"""## 方法1: SVM"""

from sklearn import svm
clf_s = svm.SVC(kernel='linear',C=1)
clf_s.fit(x_feature_std, x_model_year)
predicted = clf_s.predict(y_feature_std)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_model_year, predicted)

#SVMの可視化をさせます。
!pip install mlxtend --upgrade --no-deps
import numpy as np
import matplotlib.pyplot as plt
from mlxtend.plotting import plot_decision_regions
plt.style.use('ggplot')

feature_combined_std = np.vstack((x_feature_std, y_feature_std))
model_year_combined = np.hstack((x_model_year.values.T, y_model_year.values.T))
model_year_combined = np.reshape(model_year_combined,(-1))

fig = plt.figure(figsize=(13,8))
plot_decision_regions(feature_combined_std, model_year_combined, clf=clf_s)
plt.xlabel('acceleration')
plt.ylabel('MPG')
plt.show()

"""右上部分には年式が新しくて、燃費も加速度もいい車なので、買うとしたら、その辺の車を買おうと思います。
他の年式、燃費と加速度のどちらが良くないことがある車を簡単に排除できるようになりました。

## 方法2: 決定木をやってみます。
"""

from sklearn import tree

clf = tree.DecisionTreeClassifier(criterion='entropy')
clf=clf.fit(x_feature, x_model_year)
predicted = clf.predict(y_feature)#yの特徴量を入力し、予測する
from sklearn.metrics import confusion_matrix
confusion_matrix(y_model_year,predicted)#yの特徴量と予測を比べる

!pip install pydotplus
!pip install graphviz
!apt-get install graphviz
!pip install six

import pydotplus
from IPython.display import Image
from six import StringIO

dot_data = StringIO()
tree.export_graphviz(clf, out_file=dot_data)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
Image(graph.create_png())

"""見づらいですので、他の方法を試します。

## 方法3: scikit-learn でクラスタ分析 (K-means 法)

自分は車の加速度、燃費および年式の三つの要素にしか興味がないですので、ここから、要素を絞りたいと思います。
"""

df=pd.read_csv('/content/drive/MyDrive/Automobile.csv')

"""燃費と加速度をそれぞれ一定値以上に設定しました。そして、万が一車が壊れた場合に修理に困らないために、生産地を日本に絞ります。"""

df1=df[(df['mpg'] >= 15) & (df['acceleration'] >= 15) & (df['origin']== 'japan')]

df1.head()

df2=df1.drop(['cylinders', 'weight', 'displacement', 'horsepower', 'model_year', 'origin'],axis=1)

df2.head()

df2.shape

from sklearn.cluster import KMeans

# Pandas のデータフレームから Numpy の行列 (Array) に変換
df2_array = np.array([df2['mpg'].tolist(),
                      df2['acceleration'].tolist(),
                       ], np.int32)

# 行列を転置
df2_array = df2_array.T

# クラスタ分析を実行 (クラスタ数=10)
pred = KMeans(n_clusters=10).fit_predict(df2_array)
pred

# Pandas のデータフレームにクラスタ番号を追加
df2['cluster_id']=pred
df2.head()

# 各クラスタに属するサンプル数の分布
df2['cluster_id'].value_counts()

# 各クラスタの平均値
for i in range(10):
  ave=df2[df2['cluster_id']==i].mean() # クラスタ番号 = i (0~9)
  print(ave)

# 可視化（積み上げ棒グラフ）
clusterinfo = pd.DataFrame()
for i in range(10):
    clusterinfo['c' + str(i)] = df2[df2['cluster_id'] == i].mean()
clusterinfo = clusterinfo.drop('cluster_id')

my_plot = clusterinfo.T.plot(kind='bar', stacked=True, title="Mean Value of 10 Clusters")
my_plot.set_xticklabels(my_plot.xaxis.get_majorticklabels(), rotation=0)

"""棒が一番高かったクラス（毎回違う）の車の燃費と加速度の平均的な総合機能が一番良いので、その中から選びたいと思います。

## 決定木再チャレンジ

なるべくコスパがよい車がいいので、条件を加えます。
"""

df3=df[(df['mpg'] >= 35) & (df['acceleration'] >= 15) & (df['origin']== 'japan')]

"""情報量が多くなると決定木が非常に見づらくなるので、自分が気にしていない要素（気筒数,排気量,馬力,重量,モデル年）を削除します。"""

df4=df3.drop(['cylinders', 'weight', 'displacement', 'horsepower',  'origin'],axis=1)

"""残りの車の数が少ないので、全部出力します。"""

df4

feature = df4.loc[:, ['acceleration', 'mpg']]#　":"は行を全部取ってくる
model_year = df4.loc[:, ['model_year']]

x_feature, y_feature, x_model_year, y_model_year = train_test_split(feature, model_year, train_size=0.8, random_state=3)

clf = tree.DecisionTreeClassifier(criterion='entropy')
clf=clf.fit(x_feature, x_model_year)
predicted = clf.predict(y_feature)#yの特徴量を入力し、予測する
from sklearn.metrics import confusion_matrix
confusion_matrix(y_model_year,predicted)#yの特徴量と予測を比べる

dot_data = StringIO()
tree.export_graphviz(clf, out_file=dot_data)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
Image(graph.create_png())

"""やはり、わかりにくいです。K-meansとSVMの方が選びやすいです。

## 結論

今回はSVM, K-means, 決定木の三種類の方法を用いて、燃費、加速度と生産地（場合によって年式の条件も加えた）がよい車のデータを分析してみました。
　SVMのマージン最大化により、データをわかりやすくいくつかのグループに分けられました。
　k-means法で、まずデータを適当なクラスタに分けた後、クラスタの平均を用いてうまい具合にデータがわかれるように調整させていきました。
　結果的に、SVMとK-meansの分析結果がわりとわかりやすかったです。その結果から見るとdatsunのブランドの車が比較的によかったです。
"""